E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\utils\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "e:\shadowfox\phase3\meditron_nlp_project\scripts\run_analysis.py", line 6, in <module>
    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline
  File "E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\__init__.py", line 27, in <module>
    from . import dependency_versions_check
  File "E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\dependency_versions_check.py", line 57, in <module>
    require_version_core(deps[pkg])
  File "E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\utils\versions.py", line 117, in require_version_core
    return require_version(requirement, hint)
  File "E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\utils\versions.py", line 111, in require_version
    _compare_versions(op, got_ver, want_ver, requirement, pkg, hint)
  File "E:\shadowfox\phase3\meditron_nlp_project\venv\lib\site-packages\transformers\utils\versions.py", line 44, in _compare_versions
    raise ImportError(
ImportError: huggingface-hub>=0.34.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.1.5.
Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main
