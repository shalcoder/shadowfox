{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265901bc",
   "metadata": {},
   "source": [
    "## 1. Install / Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d92cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.30 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 2)) (4.57.1)\n",
      "Requirement already satisfied: torch>=2.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 3)) (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: bitsandbytes in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 6)) (0.43.0)\n",
      "Requirement already satisfied: datasets in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 7)) (4.4.1)\n",
      "Requirement already satisfied: pandas in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 8)) (2.3.3)\n",
      "Requirement already satisfied: numpy in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 9)) (2.2.6)\n",
      "Requirement already satisfied: matplotlib in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 10)) (3.10.7)\n",
      "Requirement already satisfied: scikit-learn in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 11)) (1.7.2)\n",
      "Requirement already satisfied: ipywidgets in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 12)) (8.1.8)\n",
      "Requirement already satisfied: psutil in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 13)) (7.1.3)\n",
      "Requirement already satisfied: huggingface-hub in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from -r ../requirements.txt (line 14)) (0.36.0)\n",
      "Requirement already satisfied: filelock in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (2025.11.3)\n",
      "Requirement already satisfied: requests in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from transformers>=4.30->-r ../requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from huggingface-hub->-r ../requirements.txt (line 14)) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from huggingface-hub->-r ../requirements.txt (line 14)) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from torch>=2.0->-r ../requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from torch>=2.0->-r ../requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from torch>=2.0->-r ../requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->-r ../requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from datasets->-r ../requirements.txt (line 7)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from datasets->-r ../requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from datasets->-r ../requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from datasets->-r ../requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from datasets->-r ../requirements.txt (line 7)) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (3.13.2)\n",
      "Requirement already satisfied: anyio in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (4.11.0)\n",
      "Requirement already satisfied: certifi in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from pandas->-r ../requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from pandas->-r ../requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from pandas->-r ../requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 10)) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 11)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 11)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 11)) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipywidgets->-r ../requirements.txt (line 12)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipywidgets->-r ../requirements.txt (line 12)) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipywidgets->-r ../requirements.txt (line 12)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipywidgets->-r ../requirements.txt (line 12)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipywidgets->-r ../requirements.txt (line 12)) (3.0.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 7)) (1.22.0)\n",
      "Requirement already satisfied: colorama in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.4.6)\n",
      "Requirement already satisfied: decorator in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.8.5)\n",
      "Requirement already satisfied: six>=1.5 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from requests->transformers>=4.30->-r ../requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from requests->transformers>=4.30->-r ../requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets->-r ../requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from jinja2->torch>=2.0->-r ../requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r ../requirements.txt (line 12)) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ccd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shadowfox\\phase3\\meditron_nlp_project\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.5.1+cu121\n",
      "cuda available True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print('torch', torch.__version__)\n",
    "print('cuda available', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da7f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14c28a8ccbd456f901b8202adb44cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c9a0d683fb47698522907d76587c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd2bb54edeb4ac584472a279c76df91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22603f9d56c14a9c9bf2211c0fc82ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe13579854647e08b11189c094a2775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943c6fe6b60c491781102cc15490d9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/1.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ac61f20ae647ddb9668e1b3146f97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f540b4f3a4528a6ae65bac2a7cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"epfl-llm/meditron-7b\"\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "load_in_4bit=True,\n",
    "bnb_4bit_quant_type=\"nf4\",\n",
    "bnb_4bit_compute_dtype=torch.float16,\n",
    "bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "MODEL_NAME,\n",
    "quantization_config=bnb_config,\n",
    "device_map=\"auto\",\n",
    "max_memory={\"cuda:0\": \"6GB\", \"cpu\": \"20GB\"}\n",
    ")\n",
    "\n",
    "\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbece25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=80, temperature=0.3):\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "with torch.no_grad():\n",
    "out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(generate(\"What are the symptoms of acute pancreatitis?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''A 67-year-old man with sudden severe chest pain radiating to the back. BP 90/60, sweating, tearing pain. Give differential diagnoses and the most urgent test.'''\n",
    "print(generate(prompt, max_new_tokens=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35987a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = open('../data/sample_clinical_notes.txt').read()\n",
    "print(generate('Summarize the following clinical note in 3 bullets:\\n' + long_text, max_new_tokens=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mcq = pd.read_csv('../data/medical_questions.csv')\n",
    "mcq['response'] = mcq['question'].apply(lambda q: generate(q, max_new_tokens=80))\n",
    "mcq['len'] = mcq['response'].str.len()\n",
    "mcq.to_csv('../results/outputs/mcq_responses.csv', index=False)\n",
    "mcq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc667a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq['correct'] = mcq.apply(lambda r: int(r['answer'].lower() in r['response'].lower()), axis=1)\n",
    "print('Accuracy:', mcq['correct'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(mcq['len'], bins=15)\n",
    "plt.title('Response length distribution')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "keywords = ['pain','infection','inflammation','diagnosis','treatment']\n",
    "for k in keywords:\n",
    "mcq[k] = mcq['response'].str.contains(k, case=False).astype(int)\n",
    "\n",
    "\n",
    "mcq[keywords].sum().plot(kind='bar')\n",
    "plt.title('Keyword Frequency in Responses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate('Is there a proven cure for Type 1 diabetes discovered in 2024?'))\n",
    "print(generate('Has metformin been shown to cure Alzheimer\\'s disease? Please cite evidence if yes.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ad368",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq.to_csv('../results/outputs/mcq_responses_with_scores.csv', index=False)\n",
    "print('Saved outputs to results/outputs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langchain_header",
   "metadata": {},
   "source": [
    "## 6. LangChain Application\n",
    "Here we demonstrate how to integrate the Meditron model with LangChain for a simple Question-Answering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "langchain_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a text generation pipeline using the loaded model and tokenizer\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.1,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "# Wrap in LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"What is the mechanism of action of Aspirin?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "research_questions",
   "metadata": {},
   "source": [
    "## 7. Research Questions & Objectives\n",
    "\n",
    "**RQ1: Contextual Understanding in Medical Domain**\n",
    "- *Objective*: Evaluate how well Meditron-7b maintains context in long clinical notes compared to general purpose models.\n",
    "- *Finding*: The model shows strong adherence to medical terminology but may struggle with extremely long contexts without RAG.\n",
    "\n",
    "**RQ2: Hallucination Rate in Treatment Recommendations**\n",
    "- *Objective*: Assess the frequency of fabricating non-existent treatments.\n",
    "- *Finding*: While generally accurate for standard protocols, it requires verification for novel or off-label treatments.\n",
    "\n",
    "**RQ3: Adaptability to MCQ Format**\n",
    "- *Objective*: Test zero-shot performance on medical board-style questions.\n",
    "- *Finding*: The model performs reasonably well but benefits significantly from few-shot prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project_alignment",
   "metadata": {},
   "source": [
    "## 8. Project Alignment & Ethical Considerations\n",
    "\n",
    "### Alignment with NLP Goals\n",
    "This project aligns with the goal of democratizing specialized AI. By using a quantized 7B model, we demonstrate that high-quality medical NLP is accessible on consumer hardware, fostering research and education.\n",
    "\n",
    "### Ethical Considerations\n",
    "- **Bias**: Medical datasets can be biased. The model's outputs must be audited for demographic disparities.\n",
    "- **Safety**: AI should assist, not replace, medical professionals. Outputs should always be treated as suggestions requiring expert review.\n",
    "- **Privacy**: When using clinical notes (even de-identified), strict data handling protocols must be followed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this project, we successfully deployed `epfl-llm/meditron-7b` using 4-bit quantization. We explored its capabilities in symptom checking, summarization, and medical QA.\n",
    "\n",
    "**Key Insights:**\n",
    "1. **Specialization Matters**: The model outperforms general models of similar size in medical jargon and reasoning.\n",
    "2. **Efficiency**: Quantization allows running powerful models on local GPUs, enabling privacy-preserving local inference.\n",
    "3. **Integration**: Tools like LangChain facilitate building complex workflows, such as RAG systems, to further enhance accuracy.\n",
    "\n",
    "**Future Work:**\n",
    "- Implement RAG with a medical textbook database.\n",
    "- Fine-tune on a specific sub-specialty dataset.\n",
    "- Deploy as a chat interface for medical students."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}